# Research: Bilibili Video Subtitle Synchronization

**Date**: 2025-11-19
**Feature**: 001-bilibili-subtitle-sync

## Research Questions

This document resolves the NEEDS CLARIFICATION items from the Technical Context:

1. Bilibili subtitle extraction method
2. Contract testing approach for Next.js application

---

## 1. Bilibili Subtitle Extraction Method

### Decision

Use Bilibili's public API endpoint to fetch subtitle data: `https://api.bilibili.com/x/player/v2` with video BV/AV ID, combined with subtitle file URLs from the response.

### Rationale

- **Official API**: Bilibili provides a player API that returns subtitle track URLs
- **Structured Data**: Returns JSON with subtitle metadata (language, URL)
- **No Scraping**: Avoids fragile HTML parsing that breaks with UI changes
- **CORS Handling**: Use Next.js API routes as proxy to bypass CORS restrictions
- **Format**: Subtitles are in JSON format with timing data (start, end, content)

### Implementation Approach

```typescript
// API Route: app/api/bilibili/subtitles/route.ts
// Fetches subtitle data from Bilibili API
// Returns: { tracks: [{ lang, url }], subtitles: SubtitleSegment[] }

// Client-side: services/bilibili.ts
// Calls Next.js API route to get subtitle data
// Parses subtitle JSON format into app data model
```

### Alternatives Considered

| Alternative | Pros | Cons | Rejected Because |
|-------------|------|------|------------------|
| HTML Scraping | No API dependency | Fragile, breaks with UI changes, complex parsing | High maintenance, unreliable |
| Third-party APIs | Easier integration | External dependency, rate limits, cost | Adds unnecessary complexity |
| Manual Upload | Simple implementation | Poor UX, defeats purpose | Doesn't meet requirement of URL-based loading |
| Browser Extension | Direct access to page data | Requires extension install, limited distribution | Not a web app, deployment complexity |

### Technical Details

**Bilibili API Endpoint Structure**:
- Player API: `https://api.bilibili.com/x/player/v2?bvid={BV_ID}&cid={CID}`
- Returns subtitle track list with URLs
- Subtitle files are JSON: `[{from, to, content}]` format
- Need to extract BV/AV ID and CID from video URL

**URL Parsing**:
- Format: `https://www.bilibili.com/video/BV{id}`
- Extract BV ID from URL
- Fetch video info to get CID (content ID)
- Use BV + CID to fetch subtitle data

**CORS Solution**:
- Create Next.js API route at `/api/bilibili/subtitles`
- Server-side fetch to Bilibili API (no CORS)
- Return processed data to client

---

## 2. Contract Testing Approach

### Decision

Use **Jest with contract test pattern** for localStorage interface and external API boundaries. Focus on testing the contracts between layers rather than full E2E API mocking.

### Rationale

- **Lightweight**: No additional testing framework needed (Jest already in stack)
- **Fast Execution**: Contract tests run quickly in CI/CD
- **Clear Boundaries**: Tests verify interface contracts, not implementation
- **localStorage Focus**: Primary external dependency is browser storage
- **API Mocking**: Mock Bilibili API responses with realistic fixtures

### Implementation Approach

```typescript
// __tests__/contract/storage.contract.test.ts
// Tests localStorage interface contract
// Verifies: save, load, delete operations
// Uses: jest.spyOn(Storage.prototype)

// __tests__/contract/bilibili-api.contract.test.ts
// Tests Bilibili API service contract
// Verifies: request/response shape, error handling
// Uses: MSW (Mock Service Worker) for API mocking
```

### Contract Test Coverage

1. **Storage Contract**:
   - Save highlights: `saveHighlights(videoId, highlights) => void`
   - Load highlights: `loadHighlights(videoId) => Highlight[]`
   - Clear highlights: `clearHighlights(videoId) => void`
   - Error handling: quota exceeded, parse errors

2. **Bilibili API Contract**:
   - Fetch subtitles: `fetchSubtitles(videoId) => SubtitleData`
   - Parse response: validate JSON structure
   - Error handling: network errors, invalid video ID, no subtitles

3. **Component Contracts**:
   - VideoPlayer: `onTimeUpdate(time) => void`
   - SubtitleDisplay: `onSegmentClick(segmentId) => void`
   - Props validation and callback contracts

### Alternatives Considered

| Alternative | Pros | Cons | Rejected Because |
|-------------|------|------|------------------|
| Pact (Consumer-Driven) | Industry standard, powerful | Overkill for client-only app, steep learning curve | No backend to contract with |
| OpenAPI + Prism | Auto-generated mocks | Requires OpenAPI spec, complex setup | Bilibili API not under our control |
| Full E2E only | Real integration testing | Slow, flaky, expensive | Need fast feedback for TDD |
| No contract tests | Simpler test suite | Misses integration issues | Violates constitution testing standards |

### Testing Strategy Summary

- **Unit Tests**: Components, hooks, utilities (Jest + RTL)
- **Contract Tests**: Storage interface, API boundaries (Jest + MSW)
- **Integration Tests**: User flows, multi-component interactions (Playwright)
- **Coverage Target**: 80%+ per constitution

---

## 3. State Management: Zustand

### Decision

Use **Zustand** for global state management (video playback state, subtitle data, highlights).

### Rationale

- **Lightweight**: ~1KB, minimal boilerplate
- **TypeScript**: Excellent TypeScript support
- **React Integration**: Simple hooks-based API
- **Performance**: No unnecessary re-renders
- **DevTools**: Redux DevTools integration available
- **Learning Curve**: Minimal, intuitive API

### State Structure

```typescript
// stores/videoStore.ts
interface VideoStore {
  videoId: string | null
  currentTime: number
  isPlaying: boolean
  subtitles: SubtitleSegment[]
  highlights: Set<string>
  activeSegmentId: string | null

  setVideoId: (id: string) => void
  updateTime: (time: number) => void
  togglePlay: () => void
  loadSubtitles: (subtitles: SubtitleSegment[]) => void
  toggleHighlight: (segmentId: string) => void
}
```

### Alternatives Considered

| Alternative | Pros | Cons | Rejected Because |
|-------------|------|------|------------------|
| React Context | Built-in, no dependency | Performance issues, boilerplate | Re-render problems with frequent updates |
| Redux Toolkit | Industry standard, powerful | Heavy, overkill for simple app | Too much boilerplate for small app |
| Jotai | Atomic state, flexible | Less mature, smaller ecosystem | Zustand simpler for our use case |
| useState only | Simplest | Prop drilling, hard to share state | Poor DX for cross-component state |

---

## 4. Subtitle Format Parsing

### Decision

Parse Bilibili's JSON subtitle format: `[{from: number, to: number, content: string}]` into internal data model.

### Rationale

- **Native Format**: Bilibili uses JSON, no conversion needed
- **Timing Data**: Includes start (from) and end (to) timestamps in seconds
- **Simple Structure**: Easy to parse and validate
- **No Dependencies**: Native JSON.parse sufficient

### Parser Implementation

```typescript
interface BilibiliSubtitle {
  from: number    // Start time in seconds
  to: number      // End time in seconds
  content: string // Subtitle text
}

interface SubtitleSegment {
  id: string
  startTime: number
  endTime: number
  text: string
}

function parseSubtitles(raw: BilibiliSubtitle[]): SubtitleSegment[] {
  return raw.map((item, index) => ({
    id: `subtitle-${index}`,
    startTime: item.from,
    endTime: item.to,
    text: item.content
  }))
}
```

### Edge Cases Handled

- Empty subtitle array
- Missing timing data (skip segment)
- Malformed JSON (error boundary)
- Overlapping timestamps (keep as-is, UI handles)
- Very long text (CSS truncation with expand option)

---

## 5. Performance Optimization Strategy

### Decision

Implement **virtualization for subtitle list** and **debounced playback sync** to handle 1000+ segments efficiently.

### Rationale

- **Virtualization**: Only render visible subtitle segments (react-window)
- **Debouncing**: Limit sync checks to every 100ms instead of every frame
- **Memoization**: React.memo for SubtitleSegment components
- **Lazy Loading**: Code-split video page with Next.js dynamic imports

### Implementation

```typescript
// components/SubtitleDisplay.tsx
import { FixedSizeList } from 'react-window'

// Render only visible items
<FixedSizeList
  height={600}
  itemCount={subtitles.length}
  itemSize={60}
  width="100%"
>
  {SubtitleSegmentRow}
</FixedSizeList>

// hooks/useSubtitleSync.ts
// Debounce time updates
const debouncedTime = useDebouncedValue(currentTime, 100)
```

### Performance Budgets

- Initial load: <2s (per success criteria)
- Time to interactive: <3s
- Subtitle sync delay: <500ms (per success criteria)
- Highlight interaction: <100ms (per success criteria)
- Memory: <50MB for 1000 segments

---

## 6. Accessibility Strategy

### Decision

Implement **WCAG 2.1 Level AA** compliance with keyboard navigation, ARIA labels, and screen reader support.

### Rationale

- **Constitution Requirement**: UX consistency principle requires accessibility
- **Keyboard Navigation**: Tab through segments, Enter to highlight, Space to play/pause
- **ARIA Labels**: Proper roles and labels for video player and subtitle list
- **Focus Management**: Visible focus indicators, logical tab order
- **Color Contrast**: 4.5:1 minimum for text, 3:1 for UI components

### Implementation Checklist

- [ ] Semantic HTML (button, nav, main, article)
- [ ] ARIA labels for video player controls
- [ ] Keyboard shortcuts documented
- [ ] Focus visible on all interactive elements
- [ ] Screen reader announcements for state changes
- [ ] Color contrast validation with tools
- [ ] Skip to content link
- [ ] Reduced motion support (prefers-reduced-motion)

---

---

## 7. Speech Recognition for Videos Without Subtitles

### Decision

é‡‡ç”¨**äº‘ç«¯è¯­éŸ³è¯†åˆ«æœåŠ¡ï¼ˆOpenAI Whisper APIï¼‰**ä½œä¸ºä¸»è¦æ–¹æ¡ˆï¼Œé€šè¿‡Next.js APIè·¯ç”±å¤„ç†éŸ³é¢‘æå–å’Œè¯†åˆ«ä»»åŠ¡ã€‚

### Rationale

- **å‡†ç¡®æ€§**: Whisperæ¨¡å‹åœ¨ä¸­æ–‡è¯†åˆ«ä¸Šè¡¨ç°ä¼˜å¼‚ï¼ˆWER <5%ï¼‰
- **æ—¶é—´æˆ³æ”¯æŒ**: è‡ªåŠ¨ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„å­—å¹•æ®µè½
- **å¤šè¯­è¨€æ”¯æŒ**: æ”¯æŒä¸­è‹±æ··åˆè¯†åˆ«
- **APIæˆæœ¬**: $0.006/åˆ†é’Ÿï¼Œå¯æ¥å—çš„æˆæœ¬
- **æ— éœ€å®¢æˆ·ç«¯èµ„æº**: æœåŠ¡ç«¯å¤„ç†ï¼Œä¸å ç”¨ç”¨æˆ·æµè§ˆå™¨èµ„æº
- **ç¨³å®šæ€§**: äº‘æœåŠ¡æ¯”æµè§ˆå™¨APIæ›´å¯é 

### Implementation Approach

```typescript
// app/api/bilibili/speech/route.ts
// 1. æ¥æ”¶è§†é¢‘URL
// 2. æå–éŸ³é¢‘æµï¼ˆä½¿ç”¨yt-dlpæˆ–ç±»ä¼¼å·¥å…·ï¼‰
// 3. å°†éŸ³é¢‘å‘é€åˆ°Whisper API
// 4. è§£æè¯†åˆ«ç»“æœï¼Œç”ŸæˆSubtitleSegment[]
// 5. ç¼“å­˜åˆ°IndexedDBé¿å…é‡å¤è¯†åˆ«

// Flow:
// Client â†’ Next.js API â†’ æå–éŸ³é¢‘ â†’ Whisper API â†’ è¿”å›å­—å¹•
```

### Alternatives Considered

| Alternative | Pros | Cons | Rejected Because |
|-------------|------|------|------------------|
| Web Speech API | å…è´¹ï¼Œæ— åç«¯ | å‡†ç¡®ç‡ä½ï¼ˆ<80%ï¼‰ï¼Œæ— ä¸­æ–‡ä¼˜åŒ–ï¼Œæ— æ—¶é—´æˆ³ï¼Œæµè§ˆå™¨å…¼å®¹æ€§å·® | ä¸æ»¡è¶³è´¨é‡è¦æ±‚ |
| Google Cloud Speech-to-Text | é«˜å‡†ç¡®ç‡ï¼Œæˆç†ŸæœåŠ¡ | æˆæœ¬é«˜ï¼ˆ$0.024/minï¼‰ï¼Œéœ€è¦GCPè´¦æˆ·ï¼Œé…ç½®å¤æ‚ | æˆæœ¬è¿‡é«˜ï¼ŒOpenAIæ›´ç®€å• |
| æœ¬åœ°Whisperæ¨¡å‹ | æ— APIæˆæœ¬ï¼Œéšç§å¥½ | éœ€è¦GPUæœåŠ¡å™¨ï¼Œéƒ¨ç½²å¤æ‚ï¼Œå»¶è¿Ÿé«˜ | é¡¹ç›®æ— æœåŠ¡å™¨åŸºç¡€è®¾æ–½ |
| AssemblyAI | ä¸“æ³¨è¯­éŸ³è¯†åˆ« | æˆæœ¬ç•¥é«˜ï¼ŒåŠŸèƒ½è¿‡å¤š | OpenAIè¶³å¤Ÿæ»¡è¶³éœ€æ±‚ |

### Technical Details

**éŸ³é¢‘æå–æ–¹æ¡ˆ**:
- ä½¿ç”¨**Bilibili API**è·å–éŸ³é¢‘æµURL
- æˆ–ä½¿ç”¨**you-get/yt-dlp** Pythonå·¥å…·æå–éŸ³é¢‘
- å°†éŸ³é¢‘è½¬æ¢ä¸ºWhisperæ”¯æŒçš„æ ¼å¼ï¼ˆMP3/M4A/WAVï¼‰
- é™åˆ¶éŸ³é¢‘é•¿åº¦ï¼ˆ<25MBæˆ–<2å°æ—¶ï¼‰

**APIé›†æˆ**:
```typescript
// services/speechRecognition.ts
async function transcribeAudio(audioUrl: string): Promise<SubtitleSegment[]> {
  // 1. ä¸‹è½½éŸ³é¢‘
  // 2. è°ƒç”¨OpenAI Whisper API
  // 3. è§£æå“åº”ï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
  // 4. è½¬æ¢ä¸ºSubtitleSegmentæ ¼å¼
}
```

**ç¼“å­˜ç­–ç•¥**:
- ä½¿ç”¨**IndexedDB**å­˜å‚¨è¯†åˆ«ç»“æœï¼ˆlocalStorageç©ºé—´ä¸è¶³ï¼‰
- Key: `speech-result:{videoId}`
- TTL: 30å¤©ï¼ˆè‡ªåŠ¨æ¸…ç†ï¼‰
- å­˜å‚¨å‹ç¼©åçš„JSON

**æ€§èƒ½æŒ‡æ ‡**:
- è¯†åˆ«å»¶è¿Ÿ: ~0.5xå®æ—¶ï¼ˆ5åˆ†é’Ÿè§†é¢‘çº¦2.5åˆ†é’Ÿï¼‰
- éŸ³é¢‘æå–: ~30ç§’
- æ€»ä½“ç”¨æˆ·ç­‰å¾…æ—¶é—´: ~3-4åˆ†é’Ÿ for 5åˆ†é’Ÿè§†é¢‘
- è¿›åº¦åé¦ˆ: æ˜¾ç¤º"æå–éŸ³é¢‘ä¸­...""è¯†åˆ«ä¸­..."è¿›åº¦æ¡

---

## 8. Audio Processing Strategy

### Decision

ä½¿ç”¨**æœåŠ¡ç«¯éŸ³é¢‘å¤„ç†**ï¼ˆNext.js APIè·¯ç”± + ffmpegï¼‰ï¼Œé¿å…å®¢æˆ·ç«¯å¤æ‚åº¦ã€‚

### Rationale

- **æ€§èƒ½**: æœåŠ¡ç«¯å¤„ç†æ›´å¿«ï¼Œä¸å ç”¨ç”¨æˆ·èµ„æº
- **å…¼å®¹æ€§**: é¿å…æµè§ˆå™¨å…¼å®¹æ€§é—®é¢˜
- **åŠŸèƒ½å®Œæ•´**: ffmpegæ”¯æŒæ‰€æœ‰éŸ³é¢‘æ ¼å¼è½¬æ¢
- **ç”¨æˆ·ä½“éªŒ**: åå°å¤„ç†ï¼Œç”¨æˆ·å¯ç»§ç»­æµè§ˆ
- **é”™è¯¯å¤„ç†**: æœåŠ¡ç«¯æ›´å®¹æ˜“å¤„ç†å¤æ‚é”™è¯¯

### Implementation Approach

```typescript
// app/api/bilibili/extract-audio/route.ts
import { exec } from 'child_process'
import { promisify } from 'util'

export async function POST(request: Request) {
  const { videoUrl } = await request.json()
  
  // 1. ä½¿ç”¨you-get/yt-dlpæå–éŸ³é¢‘
  // 2. è½¬æ¢ä¸ºMP3æ ¼å¼ï¼ˆffmpegï¼‰
  // 3. è¿”å›éŸ³é¢‘æ–‡ä»¶URLæˆ–Base64
}
```

### Alternatives Considered

| Alternative | Pros | Cons | Rejected Because |
|-------------|------|------|------------------|
| ffmpeg.wasm | å®¢æˆ·ç«¯å¤„ç†ï¼Œæ— éœ€æœåŠ¡å™¨ | æ…¢ï¼ˆ10x slowerï¼‰ï¼Œæµè§ˆå™¨å†…å­˜é™åˆ¶ï¼Œå¤æ‚è§†é¢‘å¯èƒ½å¤±è´¥ | æ€§èƒ½å’Œå¯é æ€§é—®é¢˜ |
| ç›´æ¥ä½¿ç”¨BilibiliéŸ³é¢‘æµ | ç®€å•ï¼Œæ— éœ€è½¬æ¢ | å¯èƒ½æœ‰CORSé—®é¢˜ï¼Œæ ¼å¼å¯èƒ½ä¸å…¼å®¹Whisper | éœ€è¦éªŒè¯å¯è¡Œæ€§ï¼Œä½œä¸ºå¤‡é€‰ |
| äº‘å‡½æ•°å¤„ç† | æŒ‰éœ€ä»˜è´¹ï¼Œå¯æ‰©å±• | éœ€è¦é¢å¤–åŸºç¡€è®¾æ–½ï¼Œå†·å¯åŠ¨å»¶è¿Ÿ | é¡¹ç›®ç®€å•ï¼Œæ— éœ€å¤æ‚æ¶æ„ |

---

## 9. Subtitle Caching Strategy

### Decision

ä½¿ç”¨**IndexedDB**å­˜å‚¨è¯­éŸ³è¯†åˆ«ç”Ÿæˆçš„å­—å¹•ï¼Œ**localStorage**å­˜å‚¨ç”¨æˆ·é«˜äº®ã€‚

### Rationale

- **å®¹é‡**: IndexedDBå¯å­˜å‚¨æ•°ç™¾MBï¼ŒlocalStorageä»…5-10MB
- **ç»“æ„åŒ–æ•°æ®**: IndexedDBæ”¯æŒç´¢å¼•å’ŒæŸ¥è¯¢
- **å¤§æ–‡ä»¶æ”¯æŒ**: é•¿è§†é¢‘çš„å­—å¹•æ•°æ®å¯èƒ½è¾ƒå¤§
- **æ€§èƒ½**: IndexedDBå¼‚æ­¥æ“ä½œï¼Œä¸é˜»å¡UI
- **localStorageä¿ç•™**: ç”¨äºè½»é‡çº§ç”¨æˆ·æ•°æ®ï¼ˆé«˜äº®ï¼‰

### Implementation Approach

```typescript
// services/indexedDBStorage.ts
class SubtitleCache {
  private db: IDBDatabase
  
  async saveSubtitles(videoId: string, subtitles: SubtitleSegment[]): Promise<void>
  async loadSubtitles(videoId: string): Promise<SubtitleSegment[] | null>
  async clearOldCache(daysOld: number): Promise<void>
}
```

### Storage Schema

**IndexedDB: `bilibili-text-db`**
- Store: `subtitles`
  - Key: videoId (string)
  - Value: { subtitles: SubtitleSegment[], source: 'native' | 'speech', createdAt: Date }
- Store: `audio-cache` (å¯é€‰ï¼Œç¼“å­˜éŸ³é¢‘æ–‡ä»¶)
  - Key: videoId
  - Value: { audioBlob: Blob, createdAt: Date }

**localStorage** (ä¿æŒç°æœ‰è®¾è®¡):
- Key: `highlights:{videoId}`
- Value: UserHighlight[]

---

## 10. Speech Recognition API Integration

### Decision

ä½¿ç”¨**OpenAI Whisper API** with `timestamp_granularities=["segment"]` é€‰é¡¹è·å–æ®µè½çº§æ—¶é—´æˆ³ã€‚

### API Details

**Endpoint**: `https://api.openai.com/v1/audio/transcriptions`

**Parameters**:
```typescript
{
  file: File | Blob,
  model: "whisper-1",
  language: "zh", // æŒ‡å®šä¸­æ–‡æå‡å‡†ç¡®ç‡
  response_format: "verbose_json", // åŒ…å«æ—¶é—´æˆ³
  timestamp_granularities: ["segment"] // æ®µè½çº§æ—¶é—´æˆ³
}
```

**Response Format**:
```json
{
  "task": "transcribe",
  "language": "zh",
  "duration": 300.0,
  "segments": [
    {
      "id": 0,
      "start": 0.0,
      "end": 3.5,
      "text": "æ¬¢è¿æ¥åˆ°bilibili",
      "tokens": [...],
      "temperature": 0.0
    }
  ]
}
```

### Rate Limits & Constraints

- **File Size**: æœ€å¤§25MB
- **Duration**: æ¨è<2å°æ—¶
- **Rate Limit**: 50 requests/minute (è¶³å¤Ÿä½¿ç”¨)
- **Cost**: $0.006/minute ($1.80 for 5å°æ—¶è§†é¢‘)
- **å¹¶å‘**: å•ç”¨æˆ·é¡ºåºå¤„ç†å³å¯

### Error Handling

```typescript
// é”™è¯¯ç±»å‹
type SpeechError = 
  | 'AUDIO_EXTRACTION_FAILED'
  | 'API_QUOTA_EXCEEDED' 
  | 'AUDIO_TOO_LARGE'
  | 'API_ERROR'
  | 'NETWORK_ERROR'

// é™çº§ç­–ç•¥
// 1. APIå¤±è´¥ â†’ æç¤ºç”¨æˆ·ï¼Œä¿å­˜è§†é¢‘IDä¾›ç¨åé‡è¯•
// 2. éŸ³é¢‘è¿‡å¤§ â†’ åˆ†æ®µå¤„ç†æˆ–æç¤ºç”¨æˆ·è§†é¢‘è¿‡é•¿
// 3. ç½‘ç»œé”™è¯¯ â†’ è‡ªåŠ¨é‡è¯•3æ¬¡ï¼ŒæŒ‡æ•°é€€é¿
```

---

## 11. User Flow for Videos Without Subtitles

### Decision

**è‡ªåŠ¨é™çº§ç­–ç•¥**ï¼šä¼˜å…ˆä½¿ç”¨åŸç”Ÿå­—å¹•ï¼Œå¦‚æ— å­—å¹•åˆ™è‡ªåŠ¨è§¦å‘è¯­éŸ³è¯†åˆ«ã€‚

### User Experience Flow

```
ç”¨æˆ·è¾“å…¥è§†é¢‘URL
  â†“
éªŒè¯URLå¹¶åŠ è½½è§†é¢‘ä¿¡æ¯
  â†“
å°è¯•è·å–åŸç”Ÿå­—å¹•
  â†“
[æœ‰å­—å¹•] â†’ ç›´æ¥ä½¿ç”¨ï¼Œæ­£å¸¸æ˜¾ç¤º
  â†“
[æ— å­—å¹•] â†’ æ˜¾ç¤ºæç¤ºï¼š"è¯¥è§†é¢‘æ— å­—å¹•ï¼Œæ­£åœ¨ç”Ÿæˆä¸­..."
  â†“
æ£€æŸ¥IndexedDBç¼“å­˜
  â†“
[æœ‰ç¼“å­˜] â†’ åŠ è½½ç¼“å­˜å­—å¹•ï¼Œæ ‡è®°"ç”±è¯­éŸ³è¯†åˆ«ç”Ÿæˆ"
  â†“
[æ— ç¼“å­˜] â†’ å¼€å§‹è¯­éŸ³è¯†åˆ«æµç¨‹
  â†“
æ˜¾ç¤ºè¿›åº¦: "æå–éŸ³é¢‘ä¸­... (30s)" 
  â†“
æ˜¾ç¤ºè¿›åº¦: "è¯†åˆ«å­—å¹•ä¸­... (60%)"
  â†“
å®Œæˆ: æ˜¾ç¤ºå­—å¹•ï¼Œä¿å­˜åˆ°IndexedDB
  â†“
ç”¨æˆ·å¯æ­£å¸¸ä½¿ç”¨ï¼ˆåŒæ­¥ã€é«˜äº®ç­‰åŠŸèƒ½ï¼‰
```

### Progress Feedback

```typescript
interface SpeechRecognitionProgress {
  status: 'extracting' | 'transcribing' | 'completed' | 'error'
  progress: number // 0-100
  message: string
  estimatedTimeRemaining?: number // ç§’
}
```

### UI Component

```typescript
// components/SpeechRecognitionStatus.tsx
<div className="speech-recognition-banner">
  <div className="status-icon">ğŸ¤</div>
  <div className="status-text">
    <p>è¯¥è§†é¢‘æ— åŸç”Ÿå­—å¹•ï¼Œæ­£åœ¨ä½¿ç”¨AIç”Ÿæˆå­—å¹•...</p>
    <ProgressBar value={progress} />
    <p className="text-sm text-gray-500">
      {status === 'extracting' && 'æå–éŸ³é¢‘ä¸­...'}
      {status === 'transcribing' && `è¯†åˆ«ä¸­... ${progress}%`}
    </p>
  </div>
</div>
```

---

## Summary

All technical clarifications resolved:

1. **Subtitle Extraction**: Bilibili API + Next.js proxy route
2. **Contract Testing**: Jest with contract pattern + MSW
3. **State Management**: Zustand for global state
4. **Subtitle Parsing**: Native JSON parsing of Bilibili format
5. **Performance**: Virtualization + debouncing + memoization
6. **Accessibility**: WCAG 2.1 AA with keyboard navigation
7. **Speech Recognition**: OpenAI Whisper API with segment timestamps
8. **Audio Processing**: Server-side with ffmpeg/yt-dlp
9. **Subtitle Caching**: IndexedDB for generated subtitles
10. **API Integration**: OpenAI Whisper API with error handling
11. **User Flow**: Auto-fallback with progress feedback

Ready to proceed to Phase 1 (Design & Contracts).
